{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "L16I9KkTM8Uk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os \n",
        "import copy\n",
        "from skimage.feature import hog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KcRP8oDyMz8I"
      },
      "outputs": [],
      "source": [
        "def non_max_suppression(boxes, overlap_thresh):\n",
        "    # If there are no boxes, return an empty list\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    # Initialize the list of picked indices\n",
        "    picked_boxes = []\n",
        "\n",
        "    # Grab the coordinates of the bounding boxes\n",
        "    boxes = np.array(boxes)\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2]\n",
        "    y2 = boxes[:, 3]\n",
        "    scores = boxes[:, 4]\n",
        "\n",
        "    # Compute the area of the bounding boxes and sort the bounding boxes by bottom-right y-coordinate\n",
        "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    idxs = scores.argsort()[::-1]\n",
        "\n",
        "    # Keep looping while some indexes still remain in the indexes list\n",
        "    while len(idxs) > 0:\n",
        "        # Grab the last index in the indexes list and add the index value to the list of picked indexes\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        picked_boxes.append(boxes[i])\n",
        "        # Find the largest (x, y) coordinates for the start of the bounding box and the smallest (x, y) coordinates for the end of the bounding box\n",
        "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "        # Compute the width and height of the bounding box\n",
        "        w = np.maximum(0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0, yy2 - yy1 + 1)\n",
        "        # Compute the ratio of overlap\n",
        "        overlap = (w * h) / area[idxs[:last]]\n",
        "        # Delete all indexes from the index list that have overlap greater than the provided overlap threshold\n",
        "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlap_thresh)[0])))\n",
        "    # Return only the bounding boxes that were picked\n",
        "    return picked_boxes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_single_scale_detector(classifier, image_path, scale_factor):\n",
        "        detections = []\n",
        "        # Load the test image\n",
        "        image = cv2.imread(image_path)\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Resize the image to a fixed size\n",
        "        resized_image = cv2.resize(gray, (100, 100))\n",
        "\n",
        "        # Detect faces using the classifier\n",
        "        faces = classifier.detectMultiScale(resized_image, scaleFactor=scale_factor, minNeighbors=5)\n",
        "\n",
        "        # Convert the coordinates to original image scale\n",
        "        for (x, y, w, h) in faces:\n",
        "            x *= (image.shape[1] / 100)\n",
        "            y *= (image.shape[0] / 100)\n",
        "            w *= (image.shape[1] / 100)\n",
        "            h *= (image.shape[0] / 100)\n",
        "            detections.append((x, y, w, h))\n",
        "\n",
        "        return detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def sliding_window(image, step_size, window_size):\n",
        "    # Slide a window across the image\n",
        "    for y in range(0, image.shape[0] - window_size[1], step_size):\n",
        "        for x in range(0, image.shape[1] - window_size[0], step_size):\n",
        "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
        "\n",
        "def detect_faces(image_path, step_size=20, window_size=(100, 100), overlap_thresh=0.3, target_size=(100, 100)):\n",
        "    \"\"\"\n",
        "    Detects faces in the given image using sliding window and non-maximum suppression techniques.\n",
        "\n",
        "    Parameters:\n",
        "    image_path (str): Path to the image file.\n",
        "    step_size (int): Step size for sliding window (default is 20).\n",
        "    window_size (tuple): Size of the sliding window (default is (100, 100)).\n",
        "    overlap_thresh (float): Overlap threshold for non-maximum suppression (default is 0.3).\n",
        "    target_size (tuple): Target size for resizing the detected face (default is (100, 100)).\n",
        "\n",
        "    Returns:\n",
        "    face_encodings (list): Encoding of the detected face.\n",
        "    \"\"\"\n",
        "    classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Initialize list to store detected faces\n",
        "    detections = []\n",
        "\n",
        "    # Loop over the sliding window\n",
        "    for (x, y, window) in sliding_window(gray, step_size, window_size):\n",
        "        # Clone the original image and get the HOG face detector\n",
        "        clone = gray.copy()\n",
        "        patch = clone[y:y + window_size[1], x:x + window_size[0]]\n",
        "\n",
        "        # Detect faces in the window\n",
        "        faces = classifier.detectMultiScale(patch, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "        # Add the bounding boxes of detected faces to the list\n",
        "        for (x1, y1, w, h) in faces:\n",
        "            detections.append((x + x1, y + y1, x + x1 + w, y + y1 + h))\n",
        "\n",
        "    # If no faces are detected, return None\n",
        "    if len(detections) == 0:\n",
        "        return None\n",
        "\n",
        "    # Select the best bounding box (currently the first one)\n",
        "    (x1, y1, x2, y2) = detections[0]\n",
        "\n",
        "    # Extract the face region\n",
        "    face = image[y1:y2, x1:x2]\n",
        "\n",
        "    # Resize the detected face to the target size\n",
        "    face_resized = cv2.resize(face, target_size)\n",
        "\n",
        "    # Return the detected face\n",
        "    return face_resized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "face = detect_faces('school/database_images/0001_c1_4.png', step_size=20, overlap_thresh=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(face)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "l1yMP6XuM_1O"
      },
      "outputs": [],
      "source": [
        "def create_database(directory):\n",
        "    \"\"\"\n",
        "    Creates and stores encodings of detected faces from images in the specified directory.\n",
        "\n",
        "    Parameters:\n",
        "    directory (str): Path to the directory containing images.\n",
        "    \"\"\"\n",
        "    face_encodings = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            image_path = os.path.join(directory, filename)\n",
        "            face = detect_faces(image_path, window_size=(100, 100))\n",
        "            if face is not None:\n",
        "                face_encodings.append(face)\n",
        "                labels.append(filename[:4])\n",
        "\n",
        "    return face_encodings, labels\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_face(face_encodings, query_encoding, labels, top_n=10):\n",
        "    \"\"\"\n",
        "    Compares the query face encoding with pre-loaded encodings to identify similar faces.\n",
        "\n",
        "    Parameters:\n",
        "    face_encodings (list): List of pre-loaded face encodings.\n",
        "    query_encoding (numpy.ndarray): Encoding of the query face.\n",
        "    top_n (int): Number of top matches to return (default is 10).\n",
        "\n",
        "    Returns:\n",
        "    sorted_results (list): Sorted list of top matched faces.\n",
        "    \"\"\"\n",
        "    distances = [np.linalg.norm(query_encoding - face) for face in face_encodings]\n",
        "    sorted_indices = np.argsort(distances)[:top_n]\n",
        "    sorted_results = [(face_encodings[i], distances[i], labels[i]) for i in sorted_indices]\n",
        "\n",
        "    return sorted_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "directory = 'school/database_images'\n",
        "face_encodings, labels = create_database(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0003', '0003', '0019', '0021', '0026', '0041', '0049', '0050', '0063', '0066', '0081', '0096', '0098', '0100', '0100', '0111', '0113', '0125', '0131', '0144', '0152', '0153']\n"
          ]
        }
      ],
      "source": [
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22\n"
          ]
        }
      ],
      "source": [
        "print(len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "for filename in os.listdir('school/query/'):\n",
        "  query_encoding = detect_faces(os.path.join('school/query/', filename))\n",
        "  if query_encoding is None:\n",
        "    predicted_labels.append('None')\n",
        "    continue\n",
        "  results = search_face(face_encodings, query_encoding, labels)\n",
        "  for face, distance, label in results:\n",
        "    predicted_labels.append(label)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['None', 'None', '0153', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '0050', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '0050', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '0049', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']\n"
          ]
        }
      ],
      "source": [
        "print(predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "F-5wnh01CFq7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rank-1 accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Function to compute rank-1 accuracy\n",
        "def compute_rank1_accuracy(true_labels, predicted_labels):\n",
        "    correct = 0\n",
        "    total = len(true_labels)\n",
        "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
        "        if true_label == predicted_label[0]:\n",
        "            correct += 1\n",
        "    rank1_accuracy = correct / total\n",
        "    return rank1_accuracy\n",
        "\n",
        "# Sample true labels and predicted labels\n",
        "true_labels = ['0001', '0002', '0003', '0004', '0005', '0006', '0007', '0008', '0009', '0010', '0011', '0012', '0013', '0014', '0015',\n",
        "               '0016', '0017', '0018', '0019', '0020', '0021', '0022', '0023', '0024', '0025', '0026', '0027', '0028', '0029', '0030',\n",
        "               '0031', '0032', '0033', '0034', '0035', '0036', '0037', '0038', '0039', '0040', '0041', '0042', '0043', '0044', '0045',\n",
        "               '0046', '0047', '0048', '0049', '0050', '0051', '0052', '0053', '0054', '0055', '0056', '0057', '0058', '0059', '0060',\n",
        "               '0061', '0062', '0063', '0064', '0065', '0066', '0067', '0068', '0069', '0070', '0071', '0072', '0073', '0074', '0075',\n",
        "               '0076', '0077', '0078', '0079', '0080', '0081', '0082', '0083', '0084', '0085', '0086', '0087', '0089', '0090',\n",
        "               '0091', '0092', '0093', '0094', '0095', '0096', '0097', '0098', '0099', '0100', '0101', '0102', '0103', '0104', '0105',\n",
        "               '0107', '0109', '0110', '0111', '0112', '0113', '0114', '0115', '0116', '0117', '0118', '0119', '0120',\n",
        "               '0121', '0122', '0123', '0124', '0125', '0126', '0127', '0128', '0129', '0130', '0131', '0132', '0133', '0134', '0135',\n",
        "               '0136', '0137', '0138', '0139', '0140', '0141', '0142', '0143', '0144', '0145', '0146', '0147', '0148', '0149', '0150',\n",
        "               '0151', '0152', '0153', '0154', '0155', '0156', '0157', '0158', '0159']\n",
        "\n",
        "\n",
        "# Compute rank-1 accuracy\n",
        "rank1_accuracy = compute_rank1_accuracy(true_labels, predicted_labels)\n",
        "print(\"Rank-1 accuracy:\", rank1_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaqLGN7JXMOP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rank-10 accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Function to compute rank-10 accuracy\n",
        "def compute_rank10_accuracy(true_labels, predicted_labels):\n",
        "    correct = 0\n",
        "    total = len(true_labels)\n",
        "    for true_label, predicted_label_list in zip(true_labels, predicted_labels):\n",
        "        if true_label in predicted_label_list[:10]:\n",
        "            correct += 1\n",
        "    rank10_accuracy = correct / total\n",
        "    return rank10_accuracy\n",
        "\n",
        "# Sample true labels and predicted labels (where predicted labels are lists of top 10 identities)\n",
        "true_labels = ['0001', '0002', '0003', '0004', '0005', '0006', '0007', '0008', '0009', '0010', '0011', '0012', '0013', '0014', '0015',\n",
        "               '0016', '0017', '0018', '0019', '0020', '0021', '0022', '0023', '0024', '0025', '0026', '0027', '0028', '0029', '0030',\n",
        "               '0031', '0032', '0033', '0034', '0035', '0036', '0037', '0038', '0039', '0040', '0041', '0042', '0043', '0044', '0045',\n",
        "               '0046', '0047', '0048', '0049', '0050', '0051', '0052', '0053', '0054', '0055', '0056', '0057', '0058', '0059', '0060',\n",
        "               '0061', '0062', '0063', '0064', '0065', '0066', '0067', '0068', '0069', '0070', '0071', '0072', '0073', '0074', '0075',\n",
        "               '0076', '0077', '0078', '0079', '0080', '0081', '0082', '0083', '0084', '0085', '0086', '0087', '0089', '0090',\n",
        "               '0091', '0092', '0093', '0094', '0095', '0096', '0097', '0098', '0099', '0100', '0101', '0102', '0103', '0104', '0105',\n",
        "               '0107', '0109', '0110', '0111', '0112', '0113', '0114', '0115', '0116', '0117', '0118', '0119', '0120',\n",
        "               '0121', '0122', '0123', '0124', '0125', '0126', '0127', '0128', '0129', '0130', '0131', '0132', '0133', '0134', '0135',\n",
        "               '0136', '0137', '0138', '0139', '0140', '0141', '0142', '0143', '0144', '0145', '0146', '0147', '0148', '0149', '0150',\n",
        "               '0151', '0152', '0153', '0154', '0155', '0156', '0157', '0158', '0159']\n",
        "\n",
        "\n",
        "# Compute rank-10 accuracy\n",
        "rank10_accuracy = compute_rank10_accuracy(true_labels, predicted_labels)\n",
        "print(\"Rank-10 accuracy:\", rank10_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "print(len(face_encodings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "ename": "error",
          "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[59], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m haar_cascade \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHaarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Applying the face detection method on the grayscale image \u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m faces_rect \u001b[38;5;241m=\u001b[39m haar_cascade\u001b[38;5;241m.\u001b[39mdetectMultiScale(gray_img, \u001b[38;5;241m1.1\u001b[39m, \u001b[38;5;241m9\u001b[39m) \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Iterating through rectangles of detected faces \u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m faces_rect: \n",
            "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
          ]
        }
      ],
      "source": [
        "img2 = cv2.imread('school/database_images/0001_c1_4.png')\n",
        "# Converting image to grayscale \n",
        "gray_img = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) \n",
        "  \n",
        "# Loading the required haar-cascade xml classifier file \n",
        "haar_cascade = cv2.CascadeClassifier('Haarcascade_frontalface_default.xml') \n",
        "  \n",
        "# Applying the face detection method on the grayscale image \n",
        "faces_rect = haar_cascade.detectMultiScale(gray_img, 1.1, 9) \n",
        "  \n",
        "# Iterating through rectangles of detected faces \n",
        "for (x, y, w, h) in faces_rect: \n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2) \n",
        "  \n",
        "cv2.imshow('Detected faces', img) \n",
        "  \n",
        "cv2.waitKey(0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
